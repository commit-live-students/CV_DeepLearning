{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 1 .  Introduction to Neural Style Transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit 1. What is Neural Style Transfer?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Let's start this topic in a bit unconventional way. Instead of diving in to the basics, we will first begin with applications which will lead us to the core topic.\n",
    "\n",
    "  A casual Google search for Style transfer apps gives us so many websites and apps which are using this concept. Most of these are mainly concentrated on photo styling and manipulation. Let's take the well known of the lot which was one of the firsts to apply this :\n",
    "\n",
    "**Prisma** [https://prisma-ai.com/]\n",
    "\n",
    "Have a look at the below set of images. Observe how the **input images** in column 1 and **style images** in column 2 combine to give the output **styled images** in column 3. This is something similar to what Prisma does to our pictures. Using the selected style images, our pictures are transformed to cool artworks !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Content Image &emsp; &emsp; &emsp; &emsp;|Style Image &emsp; &emsp; &emsp; &emsp;| Styled result  &emsp; &emsp; &emsp; &emsp;|\n",
    "|:-----------:|:---------:|:--------------------:|\n",
    "|![](https://bitbucket.org/ga_learning/style_transfer/raw/48db127941e04f2f66cdfd6a3ccaca9ed888d598/markdown_images/hills_1.jpg)| ![](https://bitbucket.org/ga_learning/style_transfer/raw/48db127941e04f2f66cdfd6a3ccaca9ed888d598/markdown_images/hills_2.jpg)| ![](https://bitbucket.org/ga_learning/style_transfer/raw/48db127941e04f2f66cdfd6a3ccaca9ed888d598/markdown_images/hills_3.jpg)|\n",
    "|![](https://bitbucket.org/ga_learning/style_transfer/raw/48db127941e04f2f66cdfd6a3ccaca9ed888d598/markdown_images/planets_1.jpg)| ![](https://bitbucket.org/ga_learning/style_transfer/raw/48db127941e04f2f66cdfd6a3ccaca9ed888d598/markdown_images/planets_2.jpg)| ![](https://bitbucket.org/ga_learning/style_transfer/raw/48db127941e04f2f66cdfd6a3ccaca9ed888d598/markdown_images/planets_3.jpg)|\n",
    "|![](https://bitbucket.org/ga_learning/style_transfer/raw/48db127941e04f2f66cdfd6a3ccaca9ed888d598/markdown_images/lion-1.jpg)| ![](https://bitbucket.org/ga_learning/style_transfer/raw/48db127941e04f2f66cdfd6a3ccaca9ed888d598/markdown_images/lion-2.jpg)| ![](https://bitbucket.org/ga_learning/style_transfer/raw/48db127941e04f2f66cdfd6a3ccaca9ed888d598/markdown_images/lion-3.jpg)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<pre>Fig.1.1 :Input(content)-image         Style-image            Styled(output)-image</pre>** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  With the above images in mind let's dive in to the core concept **style transfer**. Paintings are the wonders of mankind and imbibe a complex combination of content and style. Photographs are purely a tecnhical representation of the scene content. When we combine the two, we end up getting beautiful results. This process is called **artistic style transfer** or simply **style transfer**. It is a method which helps us apply the **style** of one image to the image of our choice. In the above cases the style from the paintings are mixed with our images making them look like the paintings. \n",
    "  \n",
    "  Another way of stating this is, given a reference painting (**style image**), the style transfer helps you visualise the images as if it was painted by the very same artist who painted the reference painting. The resultant images will be called **styled images**\n",
    "\n",
    "What is the term **neural** got to do with this? We will come to know in the next units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit 2. Intuition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intuition behind this is derived from the artists. Artists are good at generating pictures from imagination with a touch of their own style (shading, painting, brush strokes etc.). Style transfer tries to do exactly that. It can't imagine and neither paint. Hence it replicates the input image mixing it with the style taken from a painting. \n",
    "\n",
    "What can we make out of the styled images? A close observation reveals that they still have the same objects, outlines and features of the original image but the colours, texture, backgrounds have changed and resemble a lot with the paintings (style image). We are not losing the content of the input image even though the colours and textures have changed. There are no extra objects being added or present object being removed. This has lot to do with how the Style Transfer operates and there are 2 main factors which control this **Content** and **Style**.  \n",
    "  \n",
    "When we look at any image there are two important things to observe, the colour combinations, the objects present in the image. This means that every image can be represented by it's key charateristics like colours, texture, objects, their position, outlines, edges which help us get a gist of what the image is portraying. Keeping these charatacteristics in mind we define the content and style as follows : \n",
    "\n",
    "* **Style** of the image corresponds to characteristics which mostly represent the colours and textures in the image. This is very close to the brushwork which is generally unique for each artist. Paintings can be the best way to understand the style. Have a look at the styles of some of the famous painters below.\n",
    "\n",
    "**From DaVinci's Monalisa painting**\n",
    "\n",
    "![](https://bitbucket.org/ga_learning/style_transfer/raw/48db127941e04f2f66cdfd6a3ccaca9ed888d598/markdown_images/DaVinci_style_1.jpg)\n",
    "\n",
    "**From Edvard Munch's painting**\n",
    "\n",
    "![](https://bitbucket.org/ga_learning/style_transfer/raw/48db127941e04f2f66cdfd6a3ccaca9ed888d598/markdown_images/EdvardMunch_style1.jpg)\n",
    "    \n",
    "**From Picasso's painting**\n",
    "\n",
    "![](https://bitbucket.org/ga_learning/style_transfer/raw/48db127941e04f2f66cdfd6a3ccaca9ed888d598/markdown_images/picasso_style1.jpg)\n",
    "\n",
    "\n",
    "\n",
    "* **Content** is defined as the overall structure and higher-level components of the image like arrangement of objects, outlines, edges which are also termed as semantics of the image. This doesn't take in to account the colour combinations and mostly concentrates on the object feature, boundaries and edges. The stronger the feature, more is the probability of it coming out unscathed in the output image. Have a look at the below images cropped from famous paintings. The screaming person, the tree and the couple form the contents of the images.\n",
    "\n",
    "![](https://bitbucket.org/ga_learning/style_transfer/raw/48db127941e04f2f66cdfd6a3ccaca9ed888d598/markdown_images/content1.jpg)\n",
    "    \n",
    "![](https://bitbucket.org/ga_learning/style_transfer/raw/48db127941e04f2f66cdfd6a3ccaca9ed888d598/markdown_images/content2.jpg)\n",
    "    \n",
    "![](https://bitbucket.org/ga_learning/style_transfer/raw/48db127941e04f2f66cdfd6a3ccaca9ed888d598/markdown_images/content3.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit 3. How does it work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By this time you would surely have some questions springing up. \n",
    "\n",
    "  * How do we extract style and content from images?\n",
    "  * How do we combine it with the original image in such realistic way? This definitely doesn't look like simple addition of content and style.\n",
    "  \n",
    "When it comes to learning or extracting features from an image, the main candidate that comes to our mind is **Convolutional Neural Network(CNN)**. Style transfer uses pretrained CNN classifier to extract the content and style   efficiently. Hence the name **Neural Style Transfer**.\n",
    "\n",
    "How does CNN help with this? \n",
    "\n",
    "![](https://bitbucket.org/ga_learning/style_transfer/raw/48db127941e04f2f66cdfd6a3ccaca9ed888d598/markdown_images/VGG_Feature_maps.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<center>*Fig. 3.1: The layerwise feature-maps for pretrained CNN *</center>**\n",
    "### Extraction of content :                    \n",
    "When CNN is trained to classify images, it learns to extract complex features from images. Internally, it learns to discard unwanted features and process relevant features. This ultimately converts the input image to **feature maps**. The end layers of CNN are particularly strong in representing the content of the image. They help us extract content from the image. The layer conv5_1 in the In *Fig 3.1* depicts the presence of well defined features.\n",
    "\n",
    "### Extraction of style : \n",
    "Extracting style is trickier. CNN by default learns to represent the content towards the end layers. However, the begining layer feature maps hold the information about the colours, textures. In *Fig 3.1* layers conv1_1 and conv2_1 cleary show presence of colours. For identifying the dominant colours and textures present in the image, we extract the feature maps at a specific layer. We then find the features which are highly correlated among the feature maps for that layer ie., the features which common between the feature maps. \n",
    "\n",
    "Once the content and style is extracted, we build a **loss function** which helps to control the merging as well as smoothing the output image when coupled under a suitable **optimisation function**. Merging involves fusing of features (style,content) between the 2 images. Smoothing is required to make sure that the prominent edges in the image features appear smoothly in the output image so as to provide a painting like effect. We will learn more about the style and content losses and their optimisation in the next chapter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit 4. Applications "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Data augmentation:**\n",
    "\n",
    "  Data augmentation generally consists of translation, rotation and scale related variations. Style transfer  helps take it to a new level. Since it can fuse different styles, textures with the content of the image, we can effectively use it to alter the style of the images. This enables the model to learn the same content with different styles, textures  which makes training even more robust combined with other augmentation techniques. The paper https://arxiv.org/abs/1809.05375 deals with it. An interesting point authors make in the conclusion of the paper is that `their experiments provide evidence that CNNs are heavily reliant on texture, that texture reliance is a significant factor in domain bias, and that style augmentation is viable as a practical tool for deep learning practitioners to mitigate domain bias and reduce overfitting`\n",
    "  \n",
    "  \n",
    "* **Entertainment industries:**\n",
    "\n",
    "  Entertainment industries, especially movies utilise a lot of graphics these days to create a realistic experience. Style transfer helps fuse objects with different scenes and style with a realistic touch to it eliminating the need to spend lot of time shooting different scenes. No wonder, advancement in style transfer is going to contribute a lot in this domain.\n",
    "  \n",
    "\n",
    "* **Cool image enhancement and manipulation filters:**\n",
    "\n",
    "  Mostly the filters used in cell phone apps like Prisma which is a big hit among the people using social sites like Whatsapp, Facebook and Instagram. These filters operate on images giving the user various control over brightness, styles, smoothness and even cartoonization. \n",
    "  \n",
    "    \n",
    "\n",
    "* **Mimic behaviours of efficient systems:**\n",
    "\n",
    "  Research activities adapt similar techniques to make a system mimic the style of an individual or other efficient systems. Since style transfer networks aim at learning the styles of images, efforts are being made to understand if the same approach can be extended to the learning of human or any other system behaviour. Though this seems like a far shot idea, with the ever growing field of ML it is bound to have a breakthrough soon. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit 5. Quiz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following are the quizzes for Chapter 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Identify which of the following statements justify the definition of Style transfer** \n",
    "\n",
    "    a. Style transfer is an application of neural network\n",
    "    b. Style transfer uses image features for extracting the style and content from images\n",
    "    c. Style transfer is a technique of creating images from random data \n",
    "    d. Style transfer creates a composite image by fusing features from multiple images\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. In the following image of \"Venetian Sunset\" which of the following constitute \"Style\" of the image\n",
    "\n",
    "![](https://bitbucket.org/ga_learning/style_transfer/raw/48db127941e04f2f66cdfd6a3ccaca9ed888d598/markdown_images/Venice-Sunset-quiz.jpg)\n",
    "\n",
    "\n",
    "    a. The reddish-orange blend of the sky \n",
    "    b. The group of people \n",
    "    c. The outline of the palace \n",
    "    d. The pale blue water \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. In the same picture which of the following constitute **Content** of an image\n",
    "\n",
    "    a. The reddish-orange blend of the sky \n",
    "    b. The group of people \n",
    "    c. The outline of the palace \n",
    "    d. The pale blue water "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers :\n",
    "\n",
    "**1. a b and d** \n",
    "   - Hint : Option (c) says Style transfer creates image from random data which is wrong since Style transfer creates blended images from the style and contents of input images. All other options are self explanatory.\n",
    "\n",
    "**2. a and d** \n",
    "   - Hint : The style of an image is characterised by the colour, texture and brush strokes. Hence option (a) and (d) are the best match\n",
    "\n",
    "**3. b and c** \n",
    "   - Hint : The content of an image is characterised by the specific objects in the image. Hence option (b) and (c) are the best match"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
