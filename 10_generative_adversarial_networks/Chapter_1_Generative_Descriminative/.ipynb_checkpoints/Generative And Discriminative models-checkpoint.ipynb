{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Let me tell you a story; Once upon a time,there were two friends Gene and Dean. Both were really intelligent persons. While Gene used to be a painter a creator, Dean helps Gene to put his creations into their art gallery; he was the curator of their art gallery. Dean was very helpful in this task, because Gene was very weak in categorize his art forms into various themes. He have given this responsibility to Dean. Dean's job was to put the paintings into correct theme categories; such as portraits, landscapes, abstract, religious etc.   \n",
    "\n",
    "Once a visitor came to there category when dean was not present, visitor got a painting and want to know which theme it is? So he can put the painting in a competition. In absence of dean, gene look at  the picture but unable to categorized the art form. Gene told the visitor to leave the painting for a day to verify its theme with dean, but visitor did not agree to leave the painting with gene. Finally gene decided to recreate the painting by himself as he was pretty good in that. He created the art and and show it to dean next day. Dean see the painting and instantly told him; \"it is an Abstract form gene\". And that's how they both solved this problem.\n",
    "\n",
    "Wait! What just happened? can somebody tell me, what is this all about? I thought we would be talking about generative and discriminative models in this chapter!\n",
    "\n",
    "Well, calm down guys. I have already talked enough about it!\n",
    "\n",
    "What! When? \n",
    "\n",
    "Be patient guys, let me explain.\n",
    "\n",
    "We will learn about following topics in this chapter.\n",
    "\n",
    "- What are generative and discriminative models?\n",
    "- Different applications of generative models.\n",
    "- Different applications of disriminative models.\n",
    "\n",
    "\n",
    "# 1.1 Generative and Discriminative Models\n",
    "\n",
    "I have told you one story in previous paragraph about Gene (The painter) and Dean (The curator). So what? Well; If I tell you that Gene, the painter is none but a generative model and dean is a discriminative one, will it help you? What!!! yes guys; a generative model does the same task as gene; generative model is a painter? yeah in some sense. Generative models observes and learns the various distributions lies in input data and we recreate similar kind of data again using these kind of models. While, Discriminative models learns to classify input data into various categories using previous knowledge. \n",
    "\n",
    "Variational autoenoders (VAE) and Generative adversarial networks (GAN) are examples of generative models. while classification models such as; support vector machines (SVM), logistic regression or deep neural networks (classification networks) are the example of discriminative models.\n",
    "\n",
    "We can use networks like VAE and GAN to generate data such as; Images, Sound and texts. While SVM and classification networks could be used to categorize input data set into different categories such as; Image classification, Speech recognition, text sentiment classification.\n",
    "\n",
    "## Generative Adversarial Network (GAN)\n",
    "\n",
    "Well GAN is one of the member of convolutional neural network's family. it is the combination of a generative model and a discriminative model. We will discus about the details of them in few minutes; also we will talk about the GAN with quite detail in the next chapter. Here I will discuss why GAN?\n",
    "\n",
    "The primary task of the GAN is to generate synthetic images which looks like real. We will see how it can help us in the section applications of generative networks. Following images are generated by a GAN network. After seeing them the Why GAN? is self explanatory.\n",
    "\n",
    "<img src='1_1_GAN_generated.png'>\n",
    "\n",
    "*above image is taken from paper [Progressive Growing of GANs for Improved Quality, Stability, and Variation](https://arxiv.org/abs/1710.10196)*\n",
    "\n",
    "Yes! these images generated by a neural network; by a GAN. Can you see the details in these images, None of them belongs to real ones. this is the power of a Generative adversarial network. And in this course we will learn about how to generate such images by ourselves. \n",
    "\n",
    "\n",
    "## 1.1.1 Generative models\n",
    "\n",
    "We will start our discussion to understand generative models. As the name itself suggests that these kind of models can generate new data. But How? These networks falls in the category of unsupervised machine learning. So, these models do not required any kind of labeled dataset to train (Well they are not classifiers!). We usually train the generative models with tons of data. To make an efficient image generator; we need to use at least a million images! And trainable parameters of the models are significantly less than that! It leads model to learns significant underlying distribution present in the image data set, by ignoring redundant information. It only learns features which can be used to generate images similar to the training data set.\n",
    "\n",
    "You can question the performance of such models. Can you tell me; from following images which are real and which are fake ones?\n",
    "\n",
    "<img src='1_Faces.png' width=600>\n",
    "\n",
    "*image source: [Medium Article](https://medium.com/@kcimc/how-to-recognize-fake-ai-generated-images-4d1f6f9a2842)*\n",
    "\n",
    "Can you tell me? \n",
    "\n",
    "Well all the face images shown in above figure are generated by a Generative Adversarial Network! Do you still doubt their capability? Well, I bet you are surprised. \n",
    "\n",
    "So what are generative models? How can they learn different variations which are not present in the training data?\n",
    "\n",
    "Basically a generative model tries to predict conditional probability $P(Y|X)$ along with probability of $P(Y)$; where $X$ and $Y$ are the input and output respectively. To find out $P(Y|X)$ generative models follows bayes theorem which applies in following steps.\n",
    "\n",
    "Bayes theorem:\n",
    "\n",
    "<img src='8_bayes-theorem.png'>\n",
    "\n",
    "- It first estimate $P(X|Y)$ and $P(Y)$.\n",
    "- Then it multiplies $P(X|Y)$ and $P(Y)$.\n",
    "- Finally divide output of step 2 by $P(X)$. using Bayes theorem.\n",
    "\n",
    "Here, $P(X|Y)$ is nothing but training phase where label $Y$ is known (in case of generative models $X==Y$). $P(Y)$ is probability distribution of different classes. $P(X)$ is probability distribution of input data. \n",
    "\n",
    "In following chapters we will talk about Generative models in depth. But right now let's try to understand basic architecture of a generative models.\n",
    "\n",
    "<img src='2_GenerativeModels.png' width=500>\n",
    "\n",
    "Above model shows a basic architecture for a generative network. Basic building blocks of the network are:\n",
    "\n",
    "- Input Data.\n",
    "- Distributions Statistics of the data (Mean and Variation).\n",
    "- Sampling.\n",
    "- Reconstructed data.\n",
    "\n",
    "All other parts are belongs to a basic neural network. As this is an unsupervised learning framework you will not see any block for input labels. In these kind of network, input data serve as the labels for the training. and they try to learn input to output mapping using weights optimization!\n",
    "\n",
    "A genererative model tries to learn a distribution model similar to training data, best possible way to learn this distribution is using it's mean and standard deviation. Similar thing you can see in above figure, there is an input layer for incoming data then, a layer with arbitrary number of neurons which will learn hidden representations of the data and two more layers which you generally not see in a neural network. One of them tries to learn probability distribution stats of the different distributions present in the data; *i.e.* mean and standard deviation. And other layer, which is also known as sampling layer then generates new samples using the learned distributions stats, mostly this is a gaussian or normal distribution. Once the model learns various underlying distributions present in the data, it can generate new samples with the through output layer (Reconstructions) by just controlling the mean and deviation stats. \n",
    "\n",
    "Above model architecture is known as a variational autoencoder (VAE)! Well, we will learn about them in a separate chapter.\n",
    "\n",
    "Broadly there are two kind of generative model architectures; One, are variational autoencoders, which we have just seen; other ones are generative adversarial networks (GAN). \n",
    "\n",
    "We will discuss about GAN in a separate chapter. Here is the basic idea about them.\n",
    "\n",
    "<img src='3_gan.png' width=800>\n",
    "\n",
    "*image source: https://www.araya.org/archives/1216*\n",
    "\n",
    "A GAN is a combination of two neural networks, one known a generator and other one as descriminator. We can understand the learning process of GAN with an interesting example.\n",
    "\n",
    "There is a thief who print fake currencies and supply that to the market. Once a police men caught him and send him to jail. When he returned from the jail, this time he prints the currency with more accuracy but again got caught. Again he returned and print much better copies of the real currencies but again got, caught; Interesting part here is; he try to learn from his previous mistakes and in each attempt he generates better fake currencies until he fools the police men. \n",
    "\n",
    "So what have you learned from above example? Well, we should start a printing press to generates fake currencies! HaHa; just kidding guys. The thief of our story is the generator network while the policemen is the desriminator network.\n",
    "\n",
    "In a GAN; generator tries to produce fake samples. Discriminator tries to detect them fake with the help of real samples. Discriminator also returns an error quantity between real and fake samples so that generator can improve its generation ability. And again we enters in the game of probability distributions! yup generator actually trying to learn probability distribution similar to the real data but without using any extra layers of sampling and stats.\n",
    "\n",
    "We will talk about these two architectures (VAE and GAN) in much depth. We will learn about, how exactly these networks works, and how you can implement them by your own! Sounds interesting? Well, this is interesting.\n",
    "\n",
    "Well, we have talked enough about Generative models, now let's see some interesting applications of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1.1.2 Applications of Generative Models\n",
    "\n",
    "There are thousands of applications present of generative models; we will talk about few of them. Following are some coolest applications of generative models.\n",
    "\n",
    "### Generate Realistic Photographs\n",
    "\n",
    "Yes, Its similar to what we have seen above in fake face example. You can train a GAN to mimic real photographs. Interesting is, you can not only generate the images, but also control different kind of variations in the generated image.\n",
    "\n",
    "Using this Samsung's AI Center in Moscow has demonstrated that it can take a single image of a person and turn it into a talking head. And if watching the Mona Lisa come to life doesn't send chills down your spine, you need to check your pulse.The system takes a number of images of a person – and that number could be just one, or more for better results – and runs it through an off-the-shelf \"face landmark tracker\" to work out where the eyes, eyebrows, nose, lips and jawline are. \n",
    "\n",
    "Following is the output of this system.\n",
    "\n",
    "<img src='4_monalisa.jpg' width=600>\n",
    "*image source: https://newatlas.com/samsumg-ai-mona-lisa-photo-talking/59828/*\n",
    "\n",
    "Looks cool?\n",
    "\n",
    "### Training data generation\n",
    "\n",
    "I think Medical domain is the only domain which faces data scarcity more than any other domain. Its really difficult to get enough data to train a image classifier for medical images. There are lots of privacy issues, then many different regulations are there, and one most important thing is data variability. As every human is different, there are many variations in the physiological structures too. To solve this data scarcity, generative models could be very effective. following is an example of generating new training samples and corresponding segmentation annotation of cardiac MRI using a generative model.\n",
    "\n",
    "<img src='5_MRI.png' width=400>\n",
    "\n",
    "*image source: [Medium Article](https://medium.com/randomai/gan-for-medical-imaging-generating-images-and-annotations-8ad7c778809c)*\n",
    "\n",
    "### Image to Image translation\n",
    "\n",
    "This is one of the most interesting applications of the generative models.  Image-to-Image translation converts one image to another such as the edges of the bag to the photo image. Another interesting example of this is shown below:\n",
    "\n",
    "<img src='6_pix2pix.jpg' width=900>\n",
    "\n",
    "*image source: https://phillipi.github.io/pix2pix/*\n",
    "\n",
    "These networks known as conditional adversarial networks it is also widely known as pix2pix algorithm. These networks not only learn the mapping from input image to output image, but also learn a loss function to train this mapping. This makes it possible to apply the same generic approach to problems that traditionally would require very different loss formulations. Image-to-Image translation is also useful in applications such as colorization and super-resolution. However, many of the implementation ideas specific to the pix2pix algorithm are also relevant for those studying novel image synthesis.\n",
    "\n",
    "Well these were some cool applications of the generative models. As I have told you, we will talk in-depth about these models. In future chapters we will learn about GAN and VAE. \n",
    "\n",
    "Now let's take a dig at discriminative models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1.1.3 Discriminative Models\n",
    "\n",
    "Those machine learning models which discriminate between different categories are known as discriminative models. Every classification model is a discriminative model; for example the Random forest algorithm and a classification neural network both are discriminative models. These models falls into the category of supervised machine learning, where we already aware about the labels for each instance. \n",
    "\n",
    "A discriminative model tries to create decision boundaries between different classes or categories using underlying features in the data set. These models do not create new samples as there is no provision of learning probability distributions similar to generative models.\n",
    "\n",
    "In contrast a discriminator try to predict conditional probability of $P(Y|X)$ where $X$ are input features using this the classifier predicts $Y$. A discriminative classifier tries to model by just depending on the observed data. It makes fewer assumptions on the distributions but depends heavily on the quality of the data (Is it representative? Are there a lot of data?). An example is the Logistic Regression.\n",
    "\n",
    "Following is an architecture of dicriminator network.\n",
    "\n",
    "<img src='7_Descriminator.png'>\n",
    "\n",
    "Looks Familiar? Yup, This is a convolutional neural network for classification. It contains some convolution layer, some max-pooling layers and few dense layer to generate predictions over input data. We will use the same architecture in chapter 4, where we will talk about GAN.\n",
    "\n",
    "## 1.1.4 Applications of Discriminative models\n",
    "\n",
    "Applications of discriminative models are pretty clear with their explanation. As these are classifiers we can use these model whenever we need to categorize data set in different classes. Following are some applications of discriminative models.\n",
    "\n",
    "### Image Classification\n",
    "\n",
    "Yup, the first one and one of the most important applications of discriminators is in image classification. Image classification is the task of assigning an input image one label from a fixed set of categories. This is one of the core problems in Computer Vision that, despite its simplicity, has a large variety of practical applications. Moreover, as we will see later in the course, many other seemingly distinct Computer Vision tasks (such as object detection, segmentation) can be reduced to image classification.\n",
    "\n",
    "For example, in the image below an image classification model takes a single image and assigns probabilities to 4 labels, {cat, dog, hat, mug}. As shown in the image, keep in mind that to a computer an image is represented as one large 3-dimensional array of numbers. In this example, the cat image is 248 pixels wide, 400 pixels tall, and has three color channels Red,Green,Blue (or RGB for short). Therefore, the image consists of 248 x 400 x 3 numbers, or a total of 297,600 numbers. Each number is an integer that ranges from 0 (black) to 255 (white). Our task is to turn this quarter of a million numbers into a single label, such as “cat”.\n",
    "\n",
    "<img src='9_classify.png'>\n",
    "\n",
    "### Object Detection and Recognition\n",
    "\n",
    "Image classification involves assigning a class label to an image, whereas object localization involves drawing a bounding box around one or more objects in an image. Object detection is more challenging and combines these two tasks and draws a bounding box around each object of interest in the image and assigns them a class label. Together, all of these problems are referred to as object recognition.\n",
    "\n",
    "One further extension to this breakdown of computer vision tasks is object segmentation, also called \"object instance segmentation\" or \"semantic segmentation,\" where instances of recognized objects are indicated by highlighting the specific pixels of the object instead of a coarse bounding box.\n",
    "\n",
    "<img src='10_object_detection.png'>\n",
    "\n",
    "*https://blog.paralleldots.com/market-research/how-visual-object-detection-can-transform-manufacturing-industries/*\n",
    "\n",
    "Following classifier algorithms are very useful for performing such tasks.\n",
    "\n",
    "- Region based Convolutional Neural Network; RCNN.\n",
    "- Faster version of RCNN or F-RCNN.\n",
    "- Instance segmentation based Mask-RCNN.\n",
    "- YOLO algorithm.\n",
    "\n",
    "Apart from these algorithms there are many more classifiers which are being used in practice for this applications. \n",
    "\n",
    "### Instance Segmentation\n",
    "\n",
    "Instance segmentation is kind of a new field. Until the age of deep learning, there weren’t a who lot of datasets for it because the algorithms were simply not good enough. These days you mainly see MSCOCO, PASCAL, CityScape, and all sorts of datasets that include a task called instance segmentation. The main idea of instance segmentation is that we have to segment out each instance of each category, so that, for example, two people in an image will have the same category label as “person” but different instance labels like “person 1” and “person 2”, as shown below.\n",
    "\n",
    "<img src='11_InstanceSegmentation.png' width=900>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1.2 Summary\n",
    "\n",
    "Cool; So we have seen what are generative and discriminative models. We have started with our two lead heroes; Gene and Dean. Where Gene has evolved himself as a generative model and Dean has evolved himself as a discriminative model. We have seen how probability theory involved in construction of generative models. Later we have seen different interesting applications of both kind of networks. We have seen how Generative networks are very good in reconstruction of data as well as in generating a new data sample. While Discriminative networks are very impressive in classification and image segmentation task. Over all both kind of algorithms have their own place of use.\n",
    "\n",
    "In future chapters we will go in-depth of GAN, autoencoders, and Variational autoencoders. In GAN we will see how generative and discriminative algorithms works together to generate numbers out of random noise. This is gonna be really interesting. \n",
    "\n",
    "So this is it for this chapter; we will meet again in next chapter with introduction of GAN; till then Good Bye and Happy learning guys!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
