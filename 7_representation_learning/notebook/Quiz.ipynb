{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Neural networks have been around since decades, but why do we refer modern neural networks as deep networks?\n",
    "\n",
    "    1 . Modern neural networks are based on huge datasets.<br>\n",
    "\n",
    "    2 . Modern neural networks are trained using GPU's. <br>\n",
    "    3 . Modern neural networks have more hidden layers. <br>\n",
    "    4 . Modern neural networks use algorithmic improvements like batch normalisation and dropout <br>\n",
    "    \n",
    "    Answer : 3 <br> Deep networks got their names because of the increase in number of layers within a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Which of the following is not true about deep networks.\n",
    "\n",
    "    1 . They have more number of parameters compared to a shallow network.<br>\n",
    "    2 . Deep networks require more computational power to train.<br>\n",
    "    3 . The features learned by a deep network are easily intepreted by humans.<br>\n",
    "    4 . The features learned by a deep network are more discriminative than the shallow network.<br>\n",
    "\n",
    "\n",
    "    Answer : 3\n",
    "    The features in the later layers of deep network are mostly abstract and it's harder for a human to intepret it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Why is dimensionality reduction is preferred as a preprocessing step to most machine learning algorithms?\n",
    "\n",
    "    a. To visualise the data and gain an insights about features.<br>\n",
    "    b. To preserve all the information contained in the data.<br>\n",
    "    c. To suppress redudant information contained in the data.<br>\n",
    "    d. To speed up computation.<br>\n",
    "\n",
    "    1 . Only A <br>\n",
    "    2 . Only B <br>\n",
    "    3 . Only A,C and D <br>\n",
    "    4 . A,B,C,D <br>\n",
    "\n",
    "    Answer: 3\n",
    "\n",
    "    (a) True,Dimensionality reduction can be used to reduce the dataset to 2/3 dimension, so that the plots can reveal properties about the features. <br>\n",
    "    (b) False,We lose information when we project it to a lower dimension, so this is not true.<br>\n",
    "    (c) True since dimensionality reduction algorithms try to suppress redudant information.<br>\n",
    "    (d) True,Reduced dimension directly results in faster computation because we have fewer numbers to deal with.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Which of the following is not true about PCA?\n",
    "\n",
    "    1 . The output of PCA can be used to feed in to classifier.<br>\n",
    "    2 . PCA is linear transformation.<br>\n",
    "    3 . PCA is a supervised method.<br>\n",
    "    4 . PCA picks the components such that they are orthogonal to each other.<br>\n",
    "\n",
    "\n",
    "Answer : 3<br>\n",
    "    PCA doesn't require any supervision.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 . Can the output of t-sne be used as input to a classifier?\n",
    "\n",
    "1 . Yes <br>\n",
    "2 . No <br>\n",
    "\n",
    "Answer: 2\n",
    "    \n",
    "    T-SNE is a non-parametric visualisation technique and it isn't a transformation like PCA. Hence it cannot be used as input to classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. What is the reason behind frequency penalisation regulariation during feature inversion?\n",
    "\n",
    "1 . It helps us create adversial examples.<br>\n",
    "2 . It helps us avoid adversial examples by suppressing high frequency components.<br>\n",
    "3 . It helps us create images similar to the ones in dataset.<br>\n",
    "4 . None of the above.<br>\n",
    "\n",
    "Answer : 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7 . Which algorithm is used to create intepretable inputs for image explanation using LIME?<br>\n",
    "\n",
    "    1 . Nearest neighbors<br>\n",
    "    2 . Edge filters<br>\n",
    "    3 . Superpixels<br>\n",
    "    4 . K-means<br>\n",
    "\n",
    "Answer : 3 Superpixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. **Which among the following is the best choice for the explanation model in LIME?**\n",
    "\n",
    "    1.Random Forests <br>\n",
    "    2.Fully Connected Shallow neural networks.<br>\n",
    "    3.Lasso regression<br>\n",
    "    4.Linear Regression<br>\n",
    "\n",
    "\n",
    "Answer:<br>\n",
    "3. Lasso Regression\n",
    "\n",
    "\n",
    "\n",
    "Explanation:<br>\n",
    "Random forests are hard to explain, Shallow neural networks might contain non-linearities which make explanations harder, Linear regression is a good choice, but LASSO regression is linear regression with regularisation which makes the resulting model sparse. A sparse model selects features that are important and hence it is the best choice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Why is presoftmax layer a better choice for activation maximisation?\n",
    "\n",
    "1 .  Softmax might change the probability of desired class. <br>\n",
    "\n",
    "2 .  Softmax might suppress the distinctive features of the class with maximum probability <br>\n",
    "\n",
    "3 .  Empirically pre-softmax layer has resulted in more crisper images. <br>\n",
    "\n",
    "4 .  Pre-softmax layer has less dimension than softmax layer. <br>\n",
    "\n",
    "\n",
    "Answer : 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Which among the following statements are true about feature  inversion? <br>\n",
    "\n",
    "\n",
    " A . Feature inversion method starts with a random image.<br>\n",
    " B . Feature invesion method starts with an image that is similar to our target image.<br>\n",
    " C . The parameters of the network are modified to reduce the loss.<br>\n",
    " D . The input image is modified keeping the parameters of the network fixed.<br>\n",
    " \n",
    " \n",
    " 1 . A and C <br>\n",
    " 2 .  Only A <br>\n",
    " 3 . A and D <br>\n",
    " 4 . Only D <br>\n",
    " \n",
    " Answer: 3 . The parameters are kept fixed and the method starts with a random image that is updated after every iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
